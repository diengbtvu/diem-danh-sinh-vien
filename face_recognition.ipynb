{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Improved Face Recognition with DeepFace (ArcFace Model)",
        "\n",
        "This notebook provides an improved face recognition solution using the DeepFace library, which integrates state-of-the-art models like ArcFace. This approach is designed to be more robust against facial changes (e.g., beard growth, skin tone variations, eyebrow modifications, nose alterations) and to better distinguish between identical twins, compared to simpler methods like YOLO-based classification.",
        "\n",
        "**Note:** Achieving 100% accuracy in real-world face recognition, especially with identical twins and significant facial alterations, is an extremely challenging, if not practically impossible, goal. While state-of-the-art models like ArcFace offer very high accuracy, they are still subject to limitations based on data quality, environmental factors, and the inherent similarities between individuals."
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Installation",
        "Run the following cell to install the necessary libraries. This may take a few minutes."
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_libs"
      },
      "outputs": [],
      "source": [
        "!pip install deepface rich numpy opencv-python splitfolders"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Mount Google Drive (Optional)",
        "If your dataset is stored in Google Drive, run the following cell to mount your Drive. Otherwise, you can upload your dataset directly to the Colab environment."
      ],
      "metadata": {
        "id": "mount_drive"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_code"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    drive.mount(\"/content/drive\")\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Configuration and Data Preparation",
        "**Important:** You need to prepare your dataset. The `DATA_DIR` should point to a directory containing subfolders, where each subfolder represents a unique identity (person), and contains images of that person.",
        "\n",
        "Example directory structure:",
        "```\n",
        "your_dataset_folder/\n",
        "  Person_A/\n",
        "    image1.jpg\n",
        "    image2.png\n",
        "  Person_B/\n",
        "    image3.jpg\n",
        "    image4.jpeg\n",
        "```\n",
        "Update `DATA_DIR` and `OUT_DIR` below to match your setup."
      ],
      "metadata": {
        "id": "config_data"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paths_and_params"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from rich import print as rprint\n",
        "import splitfolders\n",
        "\n",
        "# --- User Configuration ---\n",
        "# Path to your dataset directory. Replace with your actual path.\n",
        "# Example: `DATA_DIR = '/content/drive/MyDrive/your_face_dataset'` if using Google Drive\n",
        "DATA_DIR = './your_dataset_folder' # <--- IMPORTANT: CHANGE THIS PATH\n",
        "\n",
        "# Output directory for processed data (e.g., train/val/test splits)\n",
        "OUT_DIR = './face_recognition_data_split'\n",
        "\n",
        "# DeepFace Model Configuration\n",
        "# Recommended models for high accuracy: \"ArcFace\", \"Facenet512\"\n",
        "# Detector backends: \"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\", \"mediapipe\"\n",
        "# \"retinaface\" is generally robust.\n",
        "FACE_RECOGNITION_MODEL = \"ArcFace\"\n",
        "DETECTOR_BACKEND = \"retinaface\"\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "rprint(\"[bold red]DATA PREPARATION AND CONFIGURATION[/bold red]\")\n",
        "\n",
        "# Data splitting (Train/Validation/Test)\n",
        "if os.path.exists(OUT_DIR):\n",
        "    shutil.rmtree(OUT_DIR)\n",
        "\n",
        "rprint(\"[bold cyan]Creating dataset split (80/10/10 for train/val/test)...[/bold cyan]\")\n",
        "try:\n",
        "    splitfolders.ratio(\n",
        "        DATA_DIR,\n",
        "        output=OUT_DIR,\n",
        "        seed=SEED,\n",
        "        ratio=(0.8, 0.1, 0.1),  # Train/Val/Test split\n",
        "        group_prefix=None,\n",
        "        move=False,\n",
        "    )\n",
        "    rprint(\"[bold green]Dataset split created successfully![/bold green]\")\n",
        "except Exception as e:\n",
        "    rprint(f\"[red]Error creating dataset split: {str(e)}. Please ensure DATA_DIR is correct and contains subfolders with images.[/red]\")\n",
        "\n",
        "# Dataset statistics\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    split_dir = os.path.join(OUT_DIR, split)\n",
        "    if os.path.exists(split_dir):\n",
        "        classes = [p for p in os.listdir(split_dir) if os.path.isdir(os.path.join(split_dir, p))]\n",
        "        total_imgs = sum(len(os.listdir(os.path.join(split_dir, cls))) for cls in classes)\n",
        "        rprint(f\"{split.upper()}: {len(classes)} classes, {total_imgs:,} images\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Face Recognition Implementation with DeepFace",
        "This section defines the function to perform face recognition using DeepFace and provides a conceptual example of how to use it. In a real application, you would iterate through your test images and compare them against your training (or a separate enrollment) dataset."
      ],
      "metadata": {
        "id": "deepface_impl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "face_recognition_code"
      },
      "outputs": [],
      "source": [
        "from deepface import DeepFace\n",
        "\n",
        "# Function to perform face recognition\n",
        "def recognize_faces(img_path, db_path):\n",
        "    try:\n",
        "        # DeepFace.find returns a list of dataframes, one for each detected face in the img_path\n",
        "        # We are interested in the identity and distance.\n",
        "        dfs = DeepFace.find(\n",
        "            img_path=img_path,\n",
        "            db_path=db_path,\n",
        "            model_name=FACE_RECOGNITION_MODEL,\n",
        "            detector_backend=DETECTOR_BACKEND,\n",
        "            distance_metric=\"cosine\", # Cosine similarity is common for ArcFace\n",
        "            enforce_detection=False # Set to True if you want to skip images where no face is detected\n",
        "        )\n",
        "        return dfs\n",
        "    except Exception as e:\n",
        "        rprint(f\"[red]Error during face recognition for {img_path}: {str(e)}[/red]\")\n",
        "        return []\n",
        "\n",
        "rprint(\"[bold yellow]DEMONSTRATING FACE RECOGNITION WITH DEEPFACE:[/bold yellow]\")\n",
        "\n",
        "# --- Conceptual Usage Example ---\n",
        "# This section demonstrates how you would use the DeepFace library.\n",
        "# Replace `test_image_path` with an actual image from your test set or a new image.\n",
        "# The `db_path` should be your training data directory (or a dedicated enrollment database).\n",
        "\n",
        "# Example: Get a sample image from the test set for demonstration\n",
        "test_data_path = os.path.join(OUT_DIR, \"test\")\n",
        "test_image_path = None\n",
        "if os.path.exists(test_data_path) and os.listdir(test_data_path):\n",
        "    sample_person_dir = os.path.join(test_data_path, os.listdir(test_data_path)[0])\n",
        "    if os.path.exists(sample_person_dir) and os.listdir(sample_person_dir):\n",
        "        test_image_path = os.path.join(sample_person_dir, os.listdir(sample_person_dir)[0])\n",
        "\n",
        "if test_image_path and os.path.exists(test_image_path):\n",
        "    rprint(f\"[cyan]Attempting to recognize faces in: {test_image_path}[/cyan]\")\n",
        "    # The db_path is the directory containing subfolders of known identities (your training data)\n",
        "    results = recognize_faces(test_image_path, os.path.join(OUT_DIR, \"train\"))\n",
        "\n",
        "    if results:\n",
        "        rprint(\"[bold green]Recognition Results:[/bold green]\")\n",
        "        for df in results:\n",
        "            if not df.empty:\n",
        "                # \u0060identity\u0060 column contains the path to the matched image in the database.\n",
        "                # We can extract the person\u0027s name from the path.\n",
        "                matched_identity = Path(df[\u0027identity\u0027].iloc[0]).parent.name\n",
        "                distance = df[\u0027distance\u0027].iloc[0]\n",
        "                rprint(f\"  - Detected face matched with: [green]{matched_identity}[/green] (Distance: {distance:.4f})\")\n",
        "            else:\n",
        "                rprint(\"  - No match found for a detected face.\")\n",
        "    else:\n",
        "        rprint(\"[yellow]No faces detected or no matches found.[/yellow]\")\n",
        "else:\n",
        "    rprint(\"[red]No test image found for demonstration. Please ensure your DATA_DIR is populated and the dataset split is successful.[/red]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Further Improvements and Considerations",
        "To achieve the highest possible accuracy, especially with challenging cases like identical twins and significant facial changes, consider the following:",
        "\n",
        "*   **Large and Diverse Dataset:** A very large and diverse dataset covering various facial changes (e.g., different hairstyles, presence/absence of facial hair, aging) and numerous identical twin pairs is crucial for training and evaluating robust models.",
        "*   **Fine-tuning Pre-trained Models:** Fine-tuning pre-trained models (like ArcFace) on your specific dataset can significantly improve performance for your particular use case.",
        "*   **Active Learning/Human-in-the-Loop:** For critical applications, consider incorporating active learning or human-in-the-loop processes to handle ambiguous cases or verify challenging identifications (e.g., twin verification).",
        "*   **Real-time Optimization:** For real-time applications, optimize model inference speed using techniques like ONNX Runtime or NVIDIA TensorRT.",
        "*   **Robust Preprocessing:** Implement robust face detection and alignment as a preprocessing step to ensure consistent input to the recognition model.",
        "*   **Advanced Data Augmentation:** Explore advanced data augmentation techniques that specifically simulate facial changes (e.g., adding synthetic beards, changing skin tones, altering hairstyles) to make the model more invariant to these variations.",
        "*   **Multi-modal Approaches:** For twin recognition, consider multi-modal approaches that combine face recognition with other biometric modalities like voice recognition or gait analysis."
      ],
      "metadata": {
        "id": "improvements"
      }
    }
  ]
}


